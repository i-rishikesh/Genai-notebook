{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Agent Types & Multi-Agent Systems - Hands-On Lab\n\n**Duration**: ~3 hours\n\n## What You'll Learn\n\n\u2705 Agent Types: Reactive, Planning, Tool-Using, Hybrid  \n\u2705 Multi-Agent Patterns: Sequential, Supervisor, Hierarchical  \n\u2705 Framework Comparison: LangGraph, CrewAI, LangChain  \n\u2705 Production Best Practices: Context engineering, memory architecture  \n\u2705 Real-World Case Study: Banking fraud detection ($18.7M savings)\n\n## Prerequisites\n\n- Completed Function & Tool Calling lab\n- OpenAI API key configured\n- Understanding of LangChain and LangGraph basics\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Section 1: Introduction - What Are AI Agents?\n\n### \ud83c\udfaf Learning Objectives\n- Understand what makes an AI agent different from a chatbot\n- Learn the key characteristics of agentic AI\n- See why agents matter for business in 2025\n\n### What is an AI Agent?\n\nAn **AI agent** is an autonomous system that:\n- **Goal-oriented**: Works towards specific objectives\n- **Autonomous**: Makes decisions without constant human intervention\n- **Adaptive**: Learns and adjusts behavior based on feedback\n- **Interactive**: Engages with external environment and tools\n\n### Chatbot vs Agent\n\n**Chatbot**:\n```\nUser \u2192 LLM \u2192 Response\n```\n- Stateless, reactive\n- No goal-driven behavior\n- Limited to conversation\n\n**Agent**:\n```\nUser \u2192 Goal Definition \u2192 Planning \u2192 Tool Use \u2192 Actions \u2192 Feedback Loop \u2192 Response\n```\n- Stateful, proactive\n- Autonomous decision-making\n- Can take real-world actions\n\n### The Shift to Agentic AI (2025)\n\n**Why Now?**\n- LLMs can reliably call functions and tools\n- Frameworks matured (LangGraph 1.0, CrewAI independence)\n- Enterprise adoption accelerating\n\n**Business Value**:\n- 40-60% improved customer service resolution\n- 20-30% cost reduction\n- 96% fraud detection accuracy (vs 87% traditional)\n- $184.8B market by 2034 (35%+ CAGR)\n\n**Key Insight**: Agents transform LLMs from knowledge bases into action-taking systems"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Install required packages\n!pip install -q \\\n    langchain \\\n    langchain-openai \\\n    langchain-core \\\n    langchain-community \\\n    langgraph \\\n    langgraph-checkpoint-sqlite  # Required for checkpointing examples\n\n# Optional: Install CrewAI for Section 10 example\n# !pip install -q crewai\nprint(\"\u2705 Packages installed!\")\nprint(\"\u2139\ufe0f  Note: CrewAI is optional - uncomment above line to try Section 10 example\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Setup API key\nimport os\nfrom getpass import getpass\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n\nprint(\"\u2705 API key configured!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 2: Agent Type 1 - Reactive Agents\n\n### \ud83c\udfaf Learning Objectives\n- Understand reactive agent architecture\n- Know when to use reactive agents\n- Implement a simple reactive agent\n\n### What is a Reactive Agent?\n\n**Definition**: Agent that responds immediately to inputs without memory or planning\n\n**Characteristics**:\n- \u2705 **Fast**: Immediate response, no planning overhead\n- \u2705 **Stateless**: No memory of previous interactions\n- \u2705 **Rule-based**: Pre-defined \"if-this-then-that\" logic\n- \u274c **Context-unaware**: Each decision independent\n\n### When to Use Reactive Agents\n\n| Use Case | Example |\n|----------|---------|\n| Real-time monitoring | Temperature alerts, system health checks |\n| Instant responses | FAQ bots, simple classification |\n| High-throughput | Processing many independent requests |\n\n### Architecture\n\n```\nInput \u2192 [Reactive Agent] \u2192 Immediate Response\n       (No memory, No planning)\n```"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Reactive Agent Example: Temperature Monitor\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\n\n# Initialize LLM\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# Reactive prompt - no memory, no state\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a temperature monitoring agent. \"\n               \"If temperature > 75\u00b0F, respond 'ALERT: HIGH TEMPERATURE'. \"\n               \"Otherwise, respond 'NORMAL'.\"),\n    (\"human\", \"Current temperature: {temp}\u00b0F\")\n])\n\n# Create reactive chain\nreactive_agent = prompt | llm\n\n# Test with different temperatures\nprint(\"Test 1 (72\u00b0F):\", reactive_agent.invoke({\"temp\": 72}).content)\nprint(\"Test 2 (80\u00b0F):\", reactive_agent.invoke({\"temp\": 80}).content)\nprint(\"Test 3 (70\u00b0F):\", reactive_agent.invoke({\"temp\": 70}).content)\nprint(\"Test 4 (90\u00b0F):\", reactive_agent.invoke({\"temp\": 90}).content)\n\nprint(\"\\n\u2705 Notice: No memory of previous readings - each response is independent\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **Reactive agents are fast** - No planning or memory overhead  \n\u2705 **Best for independent tasks** - Each request processed in isolation  \n\u2705 **Stateless by design** - No context carried between invocations  \n\u274c **Limited for complex tasks** - Cannot maintain conversation or plan ahead\n\n**Real-world example**: AWS Lambda functions, API endpoint validators, system health monitors\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2.5: Quick Start with LangGraph Helpers (Recommended for Production)\n",
        "\n",
        "### The Easy Way: Helper Functions\n",
        "\n",
        "Before we dive deep into building agents from scratch, let's see the **recommended production approach** using LangGraph's prebuilt helpers.\n",
        "\n",
        "**LangChain's 2025 Recommendation**: Use helper functions first, learn manual construction later.\n",
        "\n",
        "### Why Helpers Matter\n",
        "- \u2705 **Faster Development**: 5 lines vs 30+ lines\n",
        "- \u2705 **Proven Patterns**: Battle-tested by LangChain team\n",
        "- \u2705 **Less Error-Prone**: Handles edge cases automatically\n",
        "- \u2705 **Production-Ready**: Used by majority of real-world systems\n",
        "\n",
        "### When to Use What\n",
        "| Use Helper Functions | Use Manual StateGraph |\n",
        "|---------------------|----------------------|\n",
        "| Standard ReAct agents | Custom routing logic |\n",
        "| Quick prototyping | Non-standard workflows |\n",
        "| Production code | Learning internals |\n",
        "| Tool-calling agents | Complex state management |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Define tools\n",
        "@tool\n",
        "def search_web(query: str) -> str:\n",
        "    \"\"\"Search the web for information (simulated).\"\"\"\n",
        "    return f\"Search results for '{query}': LangGraph is a framework for building stateful, multi-actor applications with LLMs.\"\n",
        "\n",
        "@tool\n",
        "def calculate(expression: str) -> str:\n",
        "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Create agent with ONE LINE\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "tools = [search_web, calculate]\n",
        "\n",
        "# This is the RECOMMENDED 2025 approach\n",
        "react_agent = create_react_agent(model, tools)\n",
        "\n",
        "# Use it\n",
        "result = react_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What is 25 * 4 and search for LangGraph?\")]\n",
        "})\n",
        "\n",
        "print(\"Agent Response:\")\n",
        "for message in result[\"messages\"]:\n",
        "    if hasattr(message, \"content\") and message.content:\n",
        "        print(f\"{message.__class__.__name__}: {message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What Just Happened?\n",
        "\n",
        "With just **one line** (`create_react_agent(model, tools)`), we got:\n",
        "- \u2705 Automatic tool calling and execution\n",
        "- \u2705 ReAct pattern (Reasoning + Acting)\n",
        "- \u2705 Proper message handling\n",
        "- \u2705 Error handling built-in\n",
        "- \u2705 Streaming support\n",
        "\n",
        "Compare this to the 30+ lines needed for manual StateGraph construction!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: create_tool_calling_agent (for models with native tool support)\n",
        "from langgraph.prebuilt import create_react_agent  # Same import for now\n",
        "\n",
        "# For newer models (GPT-4, Claude 3+), create_react_agent handles tool calling natively\n",
        "# Both approaches work - use create_react_agent as the default recommendation\n",
        "\n",
        "tool_agent = create_react_agent(model, tools)\n",
        "\n",
        "# Test with different query\n",
        "result = tool_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Calculate 100 / 5\")]\n",
        "})\n",
        "\n",
        "print(\"\\nTool Calling Result:\")\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decision Guide: Helpers vs Manual StateGraph\n",
        "\n",
        "#### \u2705 Use Helper Functions When:\n",
        "- Building standard ReAct agents (90% of use cases)\n",
        "- You need tool execution with reasoning\n",
        "- Working on production code\n",
        "- Time is limited (MVPs, prototypes)\n",
        "- Your use case matches the helper's pattern\n",
        "\n",
        "#### \ud83d\udd27 Use Manual StateGraph When:\n",
        "- You need custom routing logic (in the next sections, we'll learn this!)\n",
        "- Non-standard agent workflows\n",
        "- Learning how agents work internally\n",
        "- Complex multi-agent coordination\n",
        "- Custom state beyond messages\n",
        "\n",
        "### What We'll Learn Next\n",
        "\n",
        "In the following sections, we'll learn to build agents **from scratch** using manual StateGraph construction. This deeper knowledge will help you:\n",
        "- Understand what helpers do under the hood\n",
        "- Customize agents beyond helper capabilities\n",
        "- Debug issues when they arise\n",
        "- Build complex multi-agent systems\n",
        "\n",
        "**Production Tip**: Start with helpers, switch to manual only when you need customization the helper can't provide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 3: Agent Type 2 - Planning Agents\n\n### \ud83c\udfaf Learning Objectives\n- Understand planning agent capabilities\n- Learn ReAct (Reasoning + Acting) pattern\n- Build a planning agent\n\n### What is a Planning Agent?\n\n**Definition**: Agent that generates structured action plans before execution\n\n**Characteristics**:\n- \u2705 **Multi-step reasoning**: Breaks down goals into steps\n- \u2705 **Evaluates approaches**: Considers alternatives\n- \u2705 **Sequential planning**: Determines order of actions\n- \u2705 **Goal-directed**: Works towards defined objective\n\n### When to Use Planning Agents\n\n| Use Case | Example |\n|----------|---------|\n| Complex workflows | Trip planning, project management |\n| Strategic tasks | Investment analysis, resource allocation |\n| Multi-step processes | Data pipeline orchestration |\n\n### ReAct Pattern (Reasoning + Acting)\n\n```\n1. Thought: What do I need to do?\n2. Action: What action should I take?\n3. Observation: What did I learn?\n4. (Repeat until goal achieved)\n```"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Planning Agent Example - Modern LangGraph Approach (2025)\nfrom langgraph.graph import StateGraph, END, START\nfrom typing import TypedDict, Annotated\nfrom langchain_core.messages import HumanMessage, AIMessage\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.tools import tool\nfrom operator import add\n\n# Define tools\n@tool\ndef check_weather(location: str) -> str:\n    \"\"\"Get weather forecast for a location.\"\"\"\n    return f\"Weather in {location}: Sunny, 72\u00b0F, Low humidity\"\n\n@tool\ndef check_availability(destination: str, dates: str) -> str:\n    \"\"\"Check flight and hotel availability.\"\"\"\n    return f\"Available: Flights and hotels for {destination} on {dates}\"\n\n@tool\ndef calculate_budget(activities: str) -> str:\n    \"\"\"Estimate budget for activities.\"\"\"\n    return f\"Estimated budget for {activities}: $1,200\"\n\n# State definition\nclass PlanningState(TypedDict):\n    messages: Annotated[list, add]\n    plan_steps: list[str]\n\n# Nodes\ndef planning_node(state: PlanningState):\n    \"\"\"Analyze trip request and create plan\"\"\"\n    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", \"\"\"You are a trip planning agent. For complex tasks:\n1. Break down the goal into logical steps\n2. Plan the sequence of actions\n3. Use available tools to gather information\n4. Synthesize findings into a coherent plan\n\nAnalyze the request and create a planning strategy.\"\"\"),\n        (\"placeholder\", \"{messages}\")\n    ])\n\n    chain = prompt | llm\n    response = chain.invoke({\"messages\": state[\"messages\"]})\n    plan_steps = [\"check_weather\", \"check_availability\", \"calculate_budget\"]\n\n    print(\"\ud83d\udccb PLANNING NODE: Created travel plan strategy\")\n    return {\"messages\": [response], \"plan_steps\": plan_steps}\n\ndef tool_execution_node(state: PlanningState):\n    \"\"\"Execute tools based on plan\"\"\"\n    results = []\n    \n    # Execute tools for Tokyo spring trip\n    results.append(check_weather.invoke({\"location\": \"Tokyo\"}))\n    results.append(check_availability.invoke({\"destination\": \"Tokyo\", \"dates\": \"spring\"}))\n    results.append(calculate_budget.invoke({\"activities\": \"temples, sushi\"}))\n\n    result_text = \"\\n\".join([f\"- {r}\" for r in results])\n    print(f\"\ud83d\udd27 TOOL EXECUTION NODE: Executed {len(results)} tools\")\n    \n    return {\"messages\": [AIMessage(content=f\"Tool results:\\n{result_text}\")]}\n\ndef synthesis_node(state: PlanningState):\n    \"\"\"Create final trip plan\"\"\"\n    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", \"Synthesize the planning strategy and tool results into a comprehensive 3-day trip plan for Tokyo.\"),\n        (\"placeholder\", \"{messages}\")\n    ])\n\n    chain = prompt | llm\n    response = chain.invoke({\"messages\": state[\"messages\"]})\n    print(\"\u2705 SYNTHESIS NODE: Created final trip plan\")\n    return {\"messages\": [response]}\n\n# Build graph\nworkflow = StateGraph(PlanningState)\nworkflow.add_node(\"planning\", planning_node)\nworkflow.add_node(\"tools\", tool_execution_node)\nworkflow.add_node(\"synthesis\", synthesis_node)\n\nworkflow.add_edge(START, \"planning\")\nworkflow.add_edge(\"planning\", \"tools\")\nworkflow.add_edge(\"tools\", \"synthesis\")\nworkflow.add_edge(\"synthesis\", END)\n\nplanning_agent = workflow.compile()\n\n# Execute\nprint(\"=\" * 60)\nprint(\"PLANNING AGENT EXECUTION (LangGraph StateGraph)\")\nprint(\"=\" * 60)\n\nresult = planning_agent.invoke({\n    \"messages\": [HumanMessage(content=\"Help me plan a 3-day trip to Tokyo in spring. I want to visit temples, eat authentic sushi, and stay within budget.\")],\n    \"plan_steps\": []\n})\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PLANNING RESULT:\")\nprint(\"=\" * 60)\nprint(result[\"messages\"][-1].content)\n\nprint(\"\\n\u2705 Modern LangGraph approach: StateGraph with typed state, message-based communication, clear node separation\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **Planning agents think before acting** - Multi-step reasoning  \n\u2705 **Use ReAct pattern** - Iterative thought \u2192 action \u2192 observation  \n\u2705 **Best for complex goals** - Break down and sequence tasks  \n\u2705 **Tool integration** - Gather information to inform decisions\n\n**Real-world example**: Project management assistants, strategic advisors, research agents\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 4: Agent Type 3 - Tool-Using Agents\n\n### \ud83c\udfaf Learning Objectives\n- Understand tool-using agent capabilities\n- Implement external tool integration\n- See how tools enable real-world actions\n\n### What is a Tool-Using Agent?\n\n**Definition**: Agent that accesses and utilizes external tools to achieve goals\n\n**Characteristics**:\n- \u2705 **Environment interaction**: Can affect the real world\n- \u2705 **Tool orchestration**: Combines multiple tools\n- \u2705 **Function calling**: Structured tool invocation\n- \u2705 **Action-oriented**: Goes beyond conversation\n\n### When to Use Tool-Using Agents\n\n| Use Case | Example |\n|----------|---------|\n| System integration | CRM updates, database queries |\n| Real-world actions | Booking flights, sending emails |\n| Data retrieval | API calls, web searches |\n| Automation | Report generation, file processing |\n\n### Architecture\n\n```\nInput \u2192 [Agent] \u2192 Tool Selection \u2192 Tool Execution \u2192 Result \u2192 Agent \u2192 Output\n         \u2191                                                      \u2193\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tool Output \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Tool-Using Agent Example - Modern LangGraph with ToolNode (2025)\nfrom langgraph.graph import StateGraph, END, START\nfrom langgraph.prebuilt import ToolNode\nfrom typing import TypedDict, Annotated, Literal\nfrom langchain_core.messages import BaseMessage, HumanMessage\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\nfrom operator import add\n\n# Define tools for booking\n@tool\ndef get_weather(location: str) -> str:\n    \"\"\"Get current weather for a location.\n    \n    Args:\n        location: City name (e.g., 'Tokyo', 'Paris')\n    \"\"\"\n    # Simulated API call\n    weather_data = {\n        \"Tokyo\": \"22\u00b0C, Sunny, Cherry blossoms in bloom\",\n        \"Paris\": \"18\u00b0C, Partly cloudy\",\n        \"London\": \"15\u00b0C, Rainy\"\n    }\n    return weather_data.get(location, f\"Weather data for {location}: 20\u00b0C, Clear\")\n\n@tool\ndef book_flight(destination: str, date: str) -> str:\n    \"\"\"Book a flight to destination.\n    \n    Args:\n        destination: Destination city\n        date: Departure date (YYYY-MM-DD format)\n    \"\"\"\n    # Simulated booking\n    return f\"\u2705 Flight booked to {destination} on {date}. Confirmation: FLT-{hash(destination + date) % 10000}\"\n\n@tool\ndef book_hotel(location: str, checkin: str, nights: int = 3) -> str:\n    \"\"\"Book hotel in location.\n    \n    Args:\n        location: City name\n        checkin: Check-in date (YYYY-MM-DD)\n        nights: Number of nights (default: 3)\n    \"\"\"\n    # Simulated booking\n    return f\"\u2705 Hotel booked in {location} for {nights} nights from {checkin}. Confirmation: HTL-{hash(location) % 10000}\"\n\ntools = [get_weather, book_flight, book_hotel]\n\n# State definition\nclass AgentState(TypedDict):\n    messages: Annotated[list[BaseMessage], add]\n\n# Create tool node (LangGraph prebuilt)\ntool_node = ToolNode(tools)\n\ndef should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n    \"\"\"Determine if we need to call tools or finish\"\"\"\n    last_message = state[\"messages\"][-1]\n    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n        return \"tools\"\n    return \"end\"\n\ndef call_model(state: AgentState):\n    \"\"\"Call LLM with tool binding\"\"\"\n    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm_with_tools = llm.bind_tools(tools)\n\n    response = llm_with_tools.invoke(state[\"messages\"])\n    return {\"messages\": [response]}\n\n# Build graph\nworkflow = StateGraph(AgentState)\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"tools\", tool_node)\n\nworkflow.add_edge(START, \"agent\")\nworkflow.add_conditional_edges(\n    \"agent\",\n    should_continue,\n    {\"tools\": \"tools\", \"end\": END}\n)\nworkflow.add_edge(\"tools\", \"agent\")  # Loop back after tool execution\n\ntool_agent = workflow.compile()\n\n# Test: Complex task requiring multiple tools\nprint(\"=\" * 60)\nprint(\"TOOL-USING AGENT EXECUTION (LangGraph + ToolNode)\")\nprint(\"=\" * 60)\n\nresult = tool_agent.invoke({\n    \"messages\": [HumanMessage(content=\"I want to visit Tokyo next week (2025-12-18). Check the weather, book my flight, and reserve a hotel for 4 nights.\")]\n})\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"BOOKING RESULT:\")\nprint(\"=\" * 60)\nprint(result[\"messages\"][-1].content)\n\nprint(\"\\n\u2705 Modern LangGraph + ToolNode: Automatic tool execution loop with conditional edges\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **Tools enable real-world actions** - Beyond just conversation  \n\u2705 **Structured tool calling** - LLM generates valid function calls  \n\u2705 **Multiple tool coordination** - Agent decides which tools to use and when  \n\u2705 **Error handling** - Agent can handle tool failures gracefully\n\n**Real-world example**: GitHub Copilot, customer service automation, business process automation\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 5: Agent Type 4 - Hybrid Agents (2025 Standard)\n\n### \ud83c\udfaf Learning Objectives\n- Understand why hybrid agents are the production standard\n- Combine reactive, planning, and tool-using capabilities\n- Implement memory + planning + tools\n\n### What is a Hybrid Agent?\n\n**Definition**: Agent combining immediate response, long-term planning, and tool use with memory\n\n**Characteristics**:\n- \u2705 **Stateful**: Maintains conversation context\n- \u2705 **Planning**: Multi-step reasoning when needed\n- \u2705 **Tool access**: Can execute real-world actions\n- \u2705 **Adaptive**: Fast for simple tasks, deep reasoning for complex ones\n\n### Why Hybrid is the 2025 Standard\n\n**Business Reality**:\n- Real conversations need memory\n- Complex tasks need planning\n- Business value needs actions (tools)\n\n**Key Insight**: Production agents need all capabilities!\n\n### Architecture\n\n```\nInput \u2192 [Memory] \u2192 [Planning] \u2192 [Tool Use] \u2192 [Learning] \u2192 Output\n         \u2193           \u2193            \u2193            \u2193\n       Context    Strategy     Actions      Improvement\n```"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Hybrid Agent Example - Modern LangGraph with MemorySaver (2025)\nfrom langgraph.graph import StateGraph, END, START\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing import TypedDict, Annotated\nfrom langchain_core.messages import BaseMessage, HumanMessage, AIMessage\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.tools import tool\nfrom operator import add\n\n# Define travel tools\n@tool\ndef get_weather(location: str) -> str:\n    \"\"\"Get current weather for a location.\"\"\"\n    weather_data = {\n        \"Tokyo\": \"22\u00b0C, Sunny, Cherry blossoms in bloom\",\n        \"Japan\": \"20\u00b0C, Pleasant spring weather\"\n    }\n    return weather_data.get(location, f\"Weather data for {location}: 20\u00b0C, Clear\")\n\n@tool\ndef book_flight(destination: str, date: str) -> str:\n    \"\"\"Book a flight to destination.\"\"\"\n    return f\"\u2705 Flight booked to {destination} on {date}. Confirmation: FLT-{hash(destination + date) % 10000}\"\n\n@tool\ndef book_hotel(location: str, checkin: str, nights: int = 3) -> str:\n    \"\"\"Book hotel in location.\"\"\"\n    return f\"\u2705 Hotel booked in {location} for {nights} nights from {checkin}. Confirmation: HTL-{hash(location) % 10000}\"\n\n# State definition with memory\nclass ConversationalState(TypedDict):\n    messages: Annotated[list[BaseMessage], add]\n    user_preferences: dict\n\ndef conversational_node(state: ConversationalState):\n    \"\"\"Handle conversation with memory of preferences\"\"\"\n    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    \n    # Extract current preferences\n    preferences = state.get(\"user_preferences\", {})\n    \n    system_message = f\"\"\"You are a travel assistant with memory and planning capabilities.\n    \nCurrent user preferences: {preferences if preferences else \"None yet\"}\n\nRemember user preferences from conversation.\nPlan multi-step tasks.\nUse context to provide personalized responses.\"\"\"\n\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", system_message),\n        (\"placeholder\", \"{messages}\")\n    ])\n\n    chain = prompt | llm\n    response = chain.invoke({\"messages\": state[\"messages\"]})\n\n    # Update preferences based on conversation\n    new_preferences = preferences.copy()\n    \n    # Extract preferences from messages (simplified - production would use NLP)\n    messages_text = \" \".join([m.content for m in state[\"messages\"] if hasattr(m, \"content\")])\n    if \"japan\" in messages_text.lower() or \"tokyo\" in messages_text.lower():\n        new_preferences[\"destination\"] = \"Japan\"\n    if \"temple\" in messages_text.lower():\n        new_preferences[\"interests\"] = new_preferences.get(\"interests\", []) + [\"temples\"]\n    if \"sushi\" in messages_text.lower():\n        new_preferences[\"food\"] = new_preferences.get(\"food\", []) + [\"sushi\"]\n\n    return {\n        \"messages\": [response],\n        \"user_preferences\": new_preferences\n    }\n\n# Build graph with checkpointing\nworkflow = StateGraph(ConversationalState)\nworkflow.add_node(\"conversation\", conversational_node)\nworkflow.add_edge(\"conversation\", END)\n\n# Use MemorySaver for persistent state\nmemory = MemorySaver()\nconversational_agent = workflow.compile(checkpointer=memory)\n\nprint(\"\u2705 Hybrid agent with LangGraph MemorySaver created!\")\nprint(\"\u2139\ufe0f  Memory persisted using LangGraph checkpointing (2025 production standard)\")\nprint(\"\u2139\ufe0f  State includes conversation history AND user preferences\")"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test: Sequential conversation demonstrating memory with LangGraph\n",
        "session_id = \"travel-demo\"\n",
        "config = {\"configurable\": {\"thread_id\": session_id}}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CONVERSATION 1: Setting preferences\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "r1 = conversational_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"I want to visit Japan in spring. I love temples and sushi.\")],\n",
        "    \"user_preferences\": {}\n",
        "}, config)\n",
        "\n",
        "print(f\"User: I want to visit Japan in spring. I love temples and sushi.\")\n",
        "print(f\"Assistant: {r1['messages'][-1].content}\")\n",
        "print(f\"Stored preferences: {r1['user_preferences']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CONVERSATION 2: Using remembered context\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "r2 = conversational_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What's the weather there in April?\")],\n",
        "    \"user_preferences\": {}\n",
        "}, config)\n",
        "\n",
        "print(f\"User: What's the weather there in April?\")\n",
        "print(f\"Assistant: {r2['messages'][-1].content}\")\n",
        "print(f\"Remembered preferences: {r2['user_preferences']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CONVERSATION 3: Taking action based on preferences\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "r3 = conversational_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Book my trip for April 15th for 5 nights\")],\n",
        "    \"user_preferences\": {}\n",
        "}, config)\n",
        "\n",
        "print(f\"User: Book my trip for April 15th for 5 nights\")\n",
        "print(f\"Assistant: {r3['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n\u2705 Hybrid agent: Remembered Japan + temples + sushi across conversations!\")\n",
        "print(\"\u2139\ufe0f  Memory persisted using LangGraph MemorySaver with thread_id\")\n",
        "print(\"\u2139\ufe0f  State includes both conversation history AND user preferences\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **Hybrid = Memory + Planning + Tools** - Best of all agent types  \n\u2705 **Production standard in 2025** - Real applications need all capabilities  \n\u2705 **Stateful conversations** - Remembers user preferences and context  \n\u2705 **Intelligent task routing** - Fast for simple, deep for complex\n\n**Real-world example**: Customer support agents, personal assistants, enterprise automation\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 6: Multi-Agent Pattern 1 - Sequential\n\n### \ud83c\udfaf Learning Objectives\n- Understand sequential agent orchestration\n- Implement agent pipelines with LangGraph\n- Know when to use sequential patterns\n\n### What is a Sequential Multi-Agent Pattern?\n\n**Definition**: Agents chained in linear order, each processing previous agent's output\n\n**Characteristics**:\n- \u2705 **Linear flow**: A \u2192 B \u2192 C \u2192 D\n- \u2705 **Predictable**: Clear sequence, easy to debug\n- \u2705 **Specialized**: Each agent handles one step\n- \u2705 **Efficient**: No complex coordination overhead\n\n### When to Use Sequential Pattern\n\n| Use Case | Example |\n|----------|---------|\n| Data pipelines | Extract \u2192 Transform \u2192 Load |\n| Content workflows | Research \u2192 Write \u2192 Edit \u2192 Publish |\n| Processing chains | Parse \u2192 Validate \u2192 Enrich \u2192 Store |\n\n### Architecture with LangGraph\n\n```\n[Extract Agent] \u2192 [Summarize Agent] \u2192 [Report Agent] \u2192 Final Output\n    State            State                State\n```\n\n**Key**: State flows through each agent"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Sequential Multi-Agent Example: Document Processing Pipeline\nfrom langgraph.graph import StateGraph, END, START\nfrom typing import TypedDict\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# Define state that flows through pipeline\nclass DocumentState(TypedDict):\n    raw_text: str\n    extracted_data: str\n    summary: str\n    report: str\n\n# Agent 1: Extract key information\ndef extract_agent(state: DocumentState):\n    \"\"\"Extract structured data from raw text\"\"\"\n    prompt = f\"\"\"Extract key information from this text:\n\n{state['raw_text']}\n\nExtract: dates, names, amounts, key events. Return as bullet points.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83d\udcca EXTRACT AGENT: Extracted key data\")\n    return {\"extracted_data\": response.content}\n\n# Agent 2: Summarize\ndef summarize_agent(state: DocumentState):\n    \"\"\"Create concise summary\"\"\"\n    prompt = f\"\"\"Summarize this extracted data in 2-3 sentences:\n\n{state['extracted_data']}\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83d\udcdd SUMMARIZE AGENT: Created summary\")\n    return {\"summary\": response.content}\n\n# Agent 3: Generate report\ndef report_agent(state: DocumentState):\n    \"\"\"Generate final formatted report\"\"\"\n    prompt = f\"\"\"Create a professional report with:\n\nSummary: {state['summary']}\n\nDetails: {state['extracted_data']}\n\nFormat as markdown with sections.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83d\udcc4 REPORT AGENT: Generated final report\")\n    return {\"report\": response.content}\n\n# Build sequential pipeline with LangGraph\nworkflow = StateGraph(DocumentState)\n\n# Add nodes (agents)\nworkflow.add_node(\"extract\", extract_agent)\nworkflow.add_node(\"summarize\", summarize_agent)\nworkflow.add_node(\"report\", report_agent)\n\n\nworkflow.add_edge(START, \"extract\")\n# Define sequential edges\nworkflow.add_edge(\"extract\", \"summarize\")\nworkflow.add_edge(\"summarize\", \"report\")\nworkflow.add_edge(\"report\", END)\n\n# Set entry point\n\n# Compile pipeline\npipeline_app = workflow.compile()\n\n# Test pipeline\nraw_document = \"\"\"Meeting Notes - Q4 Planning Session\nDate: December 10, 2025\nAttendees: Sarah Chen (CEO), Mike Rodriguez (CTO), Lisa Park (CFO)\n\nKey Decisions:\n1. Approved $2.5M budget for AI infrastructure upgrade\n2. Launch new customer portal by March 2026\n3. Hire 15 engineers in Q1 2026\n4. Partnership with DataCorp finalized - $500K contract\n\nAction Items:\n- Mike: Infrastructure proposal by Dec 20\n- Lisa: Finalize Q1 budget by Dec 15\n- Sarah: Present to board on Jan 10, 2026\"\"\"\n\nprint(\"=\" * 60)\nprint(\"SEQUENTIAL PIPELINE EXECUTION\")\nprint(\"=\" * 60)\n\nresult = pipeline_app.invoke({\"raw_text\": raw_document})\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"FINAL REPORT:\")\nprint(\"=\" * 60)\nprint(result['report'])\nprint(\"\\n\u2705 Sequential pipeline: Extract \u2192 Summarize \u2192 Report\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **Sequential = Simple + Predictable** - Linear flow, easy to understand  \n\u2705 **LangGraph StateGraph** - Perfect for agent pipelines  \n\u2705 **State flows through agents** - Each agent enriches the state  \n\u2705 **Best for clear dependencies** - When step B needs step A's output\n\n**Real-world example**: ETL pipelines, content workflows, data processing chains\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 7: Multi-Agent Pattern 2 - Supervisor (Most Common)\n\n### \ud83c\udfaf Learning Objectives\n- Understand supervisor/orchestrator pattern\n- Implement dynamic task delegation\n- Learn the most common production pattern\n\n### What is a Supervisor Pattern?\n\n**Definition**: Central coordinator delegates tasks to specialized agents\n\n**Characteristics**:\n- \u2705 **Central orchestration**: One agent manages others\n- \u2705 **Dynamic routing**: Supervisor decides which agent to call\n- \u2705 **Specialization**: Each agent expert in one domain\n- \u2705 **Flexible**: Can handle various task types\n\n### Why Supervisor is Most Common (2025)\n\n**Production Reality**:\n- 60%+ of multi-agent systems use supervisor pattern\n- Balances simplicity and flexibility\n- Easy to add new specialist agents\n- Clear responsibility (supervisor = coordinator)\n\n### When to Use Supervisor Pattern\n\n| Use Case | Example |\n|----------|---------|\n| Customer support | Route to billing, tech, sales agents |\n| Research teams | Coordinator \u2192 researcher, analyst, writer |\n| Business automation | Task router \u2192 domain specialists |\n\n### Architecture\n\n```\n         [Supervisor Agent]\n                \u2193\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2193        \u2193        \u2193\n   [Agent A] [Agent B] [Agent C]\n   Research  Analysis  Writing\n       \u2193        \u2193        \u2193\n         [Back to Supervisor]\n                \u2193\n           Final Output\n```"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Supervisor Pattern Example: Research Team\nfrom langgraph.graph import StateGraph, END, START\nfrom typing import TypedDict, Literal\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# State with routing\nclass ResearchState(TypedDict):\n    task: str\n    research_findings: str\n    analysis: str\n    final_report: str\n    next_agent: str\n\n# Supervisor Agent - Routes work\ndef supervisor_agent(state: ResearchState):\n    \"\"\"Decide which specialist agent to call next\"\"\"\n    # Decision logic\n    if not state.get(\"research_findings\"):\n        decision = \"researcher\"\n        print(\"\ud83c\udfaf SUPERVISOR: Routing to RESEARCHER\")\n    elif not state.get(\"analysis\"):\n        decision = \"analyst\"\n        print(\"\ud83c\udfaf SUPERVISOR: Routing to ANALYST\")\n    elif not state.get(\"final_report\"):\n        decision = \"writer\"\n        print(\"\ud83c\udfaf SUPERVISOR: Routing to WRITER\")\n    else:\n        decision = \"FINISH\"\n        print(\"\ud83c\udfaf SUPERVISOR: All tasks complete!\")\n    \n    return {\"next_agent\": decision}\n\n# Specialist 1: Researcher\ndef researcher_agent(state: ResearchState):\n    \"\"\"Gather information on the topic\"\"\"\n    prompt = f\"\"\"Research this topic and provide key findings:\n\nTopic: {state['task']}\n\nProvide 3-5 key findings with supporting details.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83d\udcda RESEARCHER: Completed research\")\n    return {\"research_findings\": response.content}\n\n# Specialist 2: Analyst\ndef analyst_agent(state: ResearchState):\n    \"\"\"Analyze research findings\"\"\"\n    prompt = f\"\"\"Analyze these research findings:\n\n{state['research_findings']}\n\nProvide insights, patterns, and implications.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83d\udcca ANALYST: Completed analysis\")\n    return {\"analysis\": response.content}\n\n# Specialist 3: Writer\ndef writer_agent(state: ResearchState):\n    \"\"\"Write final report\"\"\"\n    prompt = f\"\"\"Write a professional report based on:\n\nTask: {state['task']}\nResearch: {state['research_findings']}\nAnalysis: {state['analysis']}\n\nCreate clear, well-structured report.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\u270d\ufe0f WRITER: Completed report\")\n    return {\"final_report\": response.content}\n\n# Build supervisor pattern\nworkflow = StateGraph(ResearchState)\n\n# Add all agents\nworkflow.add_node(\"supervisor\", supervisor_agent)\nworkflow.add_node(\"researcher\", researcher_agent)\nworkflow.add_node(\"analyst\", analyst_agent)\nworkflow.add_node(\"writer\", writer_agent)\n\n\nworkflow.add_edge(START, \"supervisor\")\n# Supervisor routes to specialists\ndef route_decision(state: ResearchState) -> Literal[\"researcher\", \"analyst\", \"writer\", \"__end__\"]:\n    next_agent = state.get(\"next_agent\", \"researcher\")\n    if next_agent == \"FINISH\":\n        return \"__end__\"\n    return next_agent\n\nworkflow.add_conditional_edges(\n    \"supervisor\",\n    route_decision,\n    {\n        \"researcher\": \"researcher\",\n        \"analyst\": \"analyst\",\n        \"writer\": \"writer\",\n        \"__end__\": END\n    })\n\n# All specialists return to supervisor\nworkflow.add_edge(\"researcher\", \"supervisor\")\nworkflow.add_edge(\"analyst\", \"supervisor\")\nworkflow.add_edge(\"writer\", \"supervisor\")\n\n# Start with supervisor\n\n# Compile\nresearch_app = workflow.compile()\n\n# Test supervisor pattern\nprint(\"=\" * 60)\nprint(\"SUPERVISOR PATTERN EXECUTION\")\nprint(\"=\" * 60)\n\nresult = research_app.invoke({\n    \"task\": \"AI agent frameworks in 2025: LangGraph vs CrewAI vs LangChain\"})\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"FINAL REPORT:\")\nprint(\"=\" * 60)\nprint(result['final_report'])\nprint(\"\\n\u2705 Supervisor coordinated 3 specialist agents dynamically!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **Supervisor = Most Common Pattern** - 60%+ of production systems  \n\u2705 **Central coordination** - One agent routes to specialists  \n\u2705 **Dynamic routing** - Supervisor decides based on state  \n\u2705 **Easy to extend** - Add new specialist agents anytime\n\n**Real-world example**: Customer service routing, research teams, enterprise workflows\n\n**Key Insight**: Supervisor pattern balances simplicity and flexibility - that's why it's #1!\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 8: Multi-Agent Pattern 3 - Hierarchical\n\n### \ud83c\udfaf Learning Objectives\n- Understand multi-layer coordination\n- Implement hierarchical agent systems\n- Know when complexity requires hierarchy\n\n### What is a Hierarchical Pattern?\n\n**Definition**: Multiple layers of supervision - planner \u2192 supervisors \u2192 specialists\n\n**Characteristics**:\n- \u2705 **Multi-layer**: Top planner \u2192 mid supervisors \u2192 specialist agents\n- \u2705 **Domain separation**: Each supervisor manages one domain\n- \u2705 **Scalable**: Can handle very complex, multi-domain tasks\n- \u2705 **Clear responsibility**: Each layer has defined role\n\n### When to Use Hierarchical Pattern\n\n| Use Case | Example |\n|----------|---------|\n| Complex processes | Insurance claims (7+ agents) |\n| Multi-domain | Enterprise systems with distinct areas |\n| Large scale | 10+ agents needed |\n\n### Real-World Example: Insurance Claims\n\n**Actual system (2025)**:\n- **Layer 1**: Planner (high-level strategy)\n- **Layer 2**: Domain supervisors (Coverage, Fraud, Payout, Audit)\n- **Layer 3**: Specialist agents (Policy checker, Fraud detector, Calculator, etc.)\n\n**Result**: Handles complex claims requiring expertise across multiple domains\n\n### Architecture\n\n```\n                [Top Planner]\n                      \u2193\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2193             \u2193             \u2193\n   [Supervisor A] [Supervisor B] [Supervisor C]\n    Coverage       Fraud         Payout\n        \u2193             \u2193             \u2193\n   \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\n   \u2193         \u2193   \u2193         \u2193   \u2193         \u2193\n[Agent 1] [Agent 2] [Agent 3] [Agent 4] [Agent 5] [Agent 6]\nPolicy   Limits   Detector  Scorer   Calc    Verify\n```"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Hierarchical Pattern Example: Simplified Claims Processing\nfrom langgraph.graph import StateGraph, END, START\nfrom typing import TypedDict\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\nclass ClaimState(TypedDict):\n    claim_description: str\n    plan: str\n    coverage_result: str\n    fraud_result: str\n    payout_amount: str\n    final_decision: str\n    next_step: str\n\n# Layer 1: Top Planner\ndef planner_agent(state: ClaimState):\n    \"\"\"High-level planning - what checks are needed?\"\"\"\n    prompt = f\"\"\"Analyze this insurance claim and plan the verification process:\n\nClaim: {state['claim_description']}\n\nDetermine what needs to be checked: coverage, fraud risk, payout calculation.\nCreate a plan.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83c\udfaf TOP PLANNER: Created verification plan\")\n    return {\"plan\": response.content, \"next_step\": \"coverage\"}\n\n# Layer 2: Coverage Supervisor\ndef coverage_supervisor(state: ClaimState):\n    \"\"\"Supervise coverage verification (would delegate to specialists)\"\"\"\n    prompt = f\"\"\"Verify insurance coverage for:\n\nClaim: {state['claim_description']}\nPlan: {state['plan']}\n\nCheck if claim is covered under policy.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\u2705 COVERAGE SUPERVISOR: Verified coverage\")\n    return {\"coverage_result\": response.content, \"next_step\": \"fraud\"}\n\n# Layer 2: Fraud Supervisor\ndef fraud_supervisor(state: ClaimState):\n    \"\"\"Supervise fraud detection (would delegate to specialists)\"\"\"\n    prompt = f\"\"\"Assess fraud risk for:\n\nClaim: {state['claim_description']}\nCoverage: {state['coverage_result']}\n\nProvide fraud risk assessment (Low/Medium/High).\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83d\udd0d FRAUD SUPERVISOR: Assessed fraud risk\")\n    return {\"fraud_result\": response.content, \"next_step\": \"payout\"}\n\n# Layer 2: Payout Supervisor\ndef payout_supervisor(state: ClaimState):\n    \"\"\"Supervise payout calculation (would delegate to specialists)\"\"\"\n    prompt = f\"\"\"Calculate payout for:\n\nClaim: {state['claim_description']}\nCoverage: {state['coverage_result']}\nFraud Risk: {state['fraud_result']}\n\nDetermine payout amount or rejection.\"\"\"\n    response = llm.invoke(prompt)\n    print(\"\ud83d\udcb0 PAYOUT SUPERVISOR: Calculated payout\")\n    return {\"payout_amount\": response.content, \"next_step\": \"finalize\"}\n\n# Final Decision\ndef finalize_decision(state: ClaimState):\n    \"\"\"Synthesize all findings into final decision\"\"\"\n    decision = f\"\"\"CLAIM DECISION\n==============\nCoverage: {state['coverage_result']}\nFraud Assessment: {state['fraud_result']}\nPayout: {state['payout_amount']}\n\nFINAL DECISION: Approved\"\"\"\n    print(\"\ud83d\udccb FINALIZE: Created final decision\")\n    return {\"final_decision\": decision, \"next_step\": \"END\"}\n\n# Build hierarchical system\nworkflow = StateGraph(ClaimState)\n\n# Add all layers\nworkflow.add_node(\"planner\", planner_agent)\nworkflow.add_node(\"coverage\", coverage_supervisor)\nworkflow.add_node(\"fraud\", fraud_supervisor)\nworkflow.add_node(\"payout\", payout_supervisor)\nworkflow.add_node(\"finalize\", finalize_decision)\n\n\nworkflow.add_edge(START, \"planner\")\n# Define hierarchical flow\ndef route_next(state: ClaimState):\n    next_step = state.get(\"next_step\", \"coverage\")\n    if next_step == \"END\":\n        return \"__end__\"\n    return next_step\n\nworkflow.add_edge(\"planner\", \"coverage\")\nworkflow.add_edge(\"coverage\", \"fraud\")\nworkflow.add_edge(\"fraud\", \"payout\")\nworkflow.add_edge(\"payout\", \"finalize\")\nworkflow.add_edge(\"finalize\", END)\n\n# Compile\nclaims_app = workflow.compile()\n\n# Test hierarchical system\nprint(\"=\" * 60)\nprint(\"HIERARCHICAL PATTERN EXECUTION\")\nprint(\"=\" * 60)\n\nclaim = \"\"\"Auto accident claim:\n- Date: Dec 10, 2025\n- Policyholder: John Smith (Policy #12345)\n- Incident: Rear-end collision, other driver at fault\n- Damages: $8,500 repairs, $1,200 medical\n- Police report filed\"\"\"\n\nresult = claims_app.invoke({\"claim_description\": claim})\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"FINAL DECISION:\")\nprint(\"=\" * 60)\nprint(result['final_decision'])\nprint(\"\\n\u2705 Hierarchical: Planner \u2192 Coverage/Fraud/Payout Supervisors \u2192 Final Decision\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **Hierarchical = Multi-Layer Supervision** - Planner \u2192 Supervisors \u2192 Specialists  \n\u2705 **Best for complex domains** - When single supervisor can't handle everything  \n\u2705 **Real-world proven** - Insurance (7 agents), Banking (12 agents)  \n\u2705 **Scalable architecture** - Can handle 10+ agents with clear structure\n\n**Real-world example**:\n- Insurance claims: 7-agent system with 3 layers\n- Banking fraud: 12-agent system with hierarchical coordination\n- Enterprise workflows: Multi-domain approval systems\n\n**Key Insight**: Use hierarchical when supervisor pattern becomes too complex!\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 9: Framework Deep Dive - LangGraph\n\n### \ud83c\udfaf Learning Objectives\n- Understand why LangGraph for multi-agent systems\n- Learn key LangGraph 1.0 features (October 2025)\n- Implement advanced patterns\n\n### Why LangGraph?\n\n**LangGraph 1.0 (October 2025)** - Production-ready release\n\n**Key Strengths**:\n- \u2705 **Fastest performance** - Lowest latency among frameworks\n- \u2705 **Precise control** - Graph-based state machines\n- \u2705 **Stateful workflows** - Built-in checkpointing\n- \u2705 **Async/distributed** - Scale to production\n\n### When to Choose LangGraph\n\n| Scenario | Why LangGraph |\n|----------|---------------|\n| Complex workflows | Need precise control over agent flow |\n| Dynamic systems | Workflows change based on state |\n| Performance critical | Lowest latency required |\n| Production scale | Enterprise features needed |\n\n### LangGraph 1.0 Features (Oct 2025)\n\n**What's New**:\n1. **Node-level caching** - Avoid redundant work\n2. **Type-safe streaming** - Better developer experience\n3. **Simplified APIs** - `addNode()`, `addSequence()`\n4. **Direct interrupt handling** - Human-in-the-loop\n5. **Enterprise stability** - Production-grade\n\n### Performance Comparison\n\n**Benchmark** (2025 tests):\n- LangGraph: ~2.3s latency\n- CrewAI: ~2.8s latency\n- LangChain: ~4.1s latency\n\n**Token Usage**:\n- LangGraph: Moderate\n- CrewAI: Low\n- LangChain: Highest"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# LangGraph Advanced Features Demo\nfrom langgraph.graph import StateGraph, END, START\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing import TypedDict\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# Feature 1: Persistent State with Checkpointing\nprint(\"=\" * 60)\nprint(\"FEATURE 1: CHECKPOINTING (Persistent State)\")\nprint(\"=\" * 60)\n\nclass AgentState(TypedDict):\n    messages: list\n    count: int\n\ndef process_step(state: AgentState):\n    count = state.get(\"count\", 0) + 1\n    messages = state.get(\"messages\", [])\n    messages.append(f\"Processed step {count}\")\n    print(f\"\u2705 Step {count} completed\")\n    return {\"messages\": messages, \"count\": count}\n\n# Create workflow with checkpointing\nworkflow = StateGraph(AgentState)\nworkflow.add_node(\"process\", process_step)\nworkflow.add_edge(\"process\", END)\n\n# Add memory (checkpointing)\nmemory = MemorySaver()\napp_with_memory = workflow.compile(checkpointer=memory)\n\n# Use with session ID for persistence\nconfig = {\"configurable\": {\"thread_id\": \"session-123\"}}\n\n# Run multiple times - state persists!\nresult1 = app_with_memory.invoke({\"messages\": [], \"count\": 0}, config)\nprint(f\"After run 1: {result1}\")\n\nresult2 = app_with_memory.invoke({\"messages\": result1[\"messages\"], \"count\": result1[\"count\"]}, config)\nprint(f\"After run 2: {result2}\")\n\nprint(\"\\n\u2705 State persisted across invocations!\")\n\n# Feature 2: Streaming for Real-Time Updates\nprint(\"\\n\" + \"=\" * 60)\nprint(\"FEATURE 2: STREAMING (Real-time Updates)\")\nprint(\"=\" * 60)\n\nclass StreamState(TypedDict):\n    step: int\n    result: str\n\ndef streaming_agent(state: StreamState):\n    step = state.get(\"step\", 0) + 1\n    result = f\"Completed step {step}\"\n    return {\"step\": step, \"result\": result}\n\nworkflow2 = StateGraph(StreamState)\nworkflow2.add_node(\"work\", streaming_agent)\nworkflow2.add_edge(\"work\", END)\nworkflow2.set_entry_point(\"work\")\nstream_app = workflow2.compile()\n\n# Stream state updates in real-time\nfor state_update in stream_app.stream({\"step\": 0}):\n    print(f\"\ud83d\udce1 Streaming update: {state_update}\")\n\nprint(\"\\n\u2705 Real-time streaming enabled!\")\n\n# Feature 3: Human-in-the-Loop (Interrupts)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"FEATURE 3: HUMAN-IN-THE-LOOP (Conceptual)\")\nprint(\"=\" * 60)\n\n# Note: Full interrupt requires user input - showing structure\nprint(\"Interrupts allow pausing agent execution for human approval:\")\nprint(\"1. Agent reaches interrupt point\")\nprint(\"2. System pauses and requests human input\")\nprint(\"3. Human approves/modifies/rejects\")\nprint(\"4. Agent continues with human decision\")\nprint(\"\\nUse case: High-stakes decisions, compliance, quality control\")\nprint(\"\\n\u2705 Interrupt system enables human oversight!\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"LANGGRAPH ADVANTAGES SUMMARY\")\nprint(\"=\" * 60)\nprint(\"\u2705 Fastest performance (lowest latency)\")\nprint(\"\u2705 Precise control via state graphs\")\nprint(\"\u2705 Built-in persistence (checkpointing)\")\nprint(\"\u2705 Real-time streaming\")\nprint(\"\u2705 Human-in-the-loop support\")\nprint(\"\u2705 Production-ready (1.0 release Oct 2025)\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **LangGraph = Speed + Control** - Fastest framework with precise workflow control  \n\u2705 **StateGraph architecture** - Explicit state machines for complex logic  \n\u2705 **Production features** - Checkpointing, streaming, interrupts  \n\u2705 **LangGraph 1.0 (Oct 2025)** - Enterprise-grade stability\n\n**Trade-off**: Steep learning curve but maximum power\n\n**When to use**: Complex workflows, performance-critical, production scale\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 10: Framework Deep Dive - CrewAI\n\n### \ud83c\udfaf Learning Objectives\n- Understand CrewAI's role-based approach\n- Learn why CrewAI is fastest to production\n- Implement teams with built-in collaboration\n\n### Why CrewAI?\n\n**CrewAI (2025 Refactor)** - Independent, enterprise-ready\n\n**Key Strengths**:\n- \u2705 **Simplest API** - Role-based teams, intuitive\n- \u2705 **Fast to production** - MVP in hours\n- \u2705 **Built-in memory** - Agents remember context\n- \u2705 **Enterprise features** - HIPAA/SOC2 compliant\n\n### When to Choose CrewAI\n\n| Scenario | Why CrewAI |\n|----------|------------|\n| Quick MVP | Need working system ASAP |\n| Role-based teams | Natural team structure |\n| Moderate complexity | Not too simple, not too complex |\n| Enterprise compliance | Need HIPAA/SOC2 |\n\n### CrewAI 2025 Features\n\n**What's New**:\n1. **Full LangChain independence** - No more dependencies\n2. **Native multimodal** - Images, audio, video\n3. **Query rewriting for RAG** - Better retrieval\n4. **Native vector DBs** - Qdrant, Pinecone, Weaviate\n5. **Enterprise compliance** - HIPAA, SOC2 certified\n\n### Performance\n\n**Speed**: Very fast (similar to LangGraph)\n**Token Usage**: Low (most efficient)\n**Learning Curve**: Easiest\n\n### Core Concepts\n\n**Agent**: Role + Goal + Backstory + Tools\n**Task**: Description + Expected Output + Agent\n**Crew**: Team of Agents + Tasks + Process"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CrewAI Example: Research Team\n",
        "# Note: Install with: pip install crewai\n",
        "\n",
        "try:\n",
        "    from crewai import Agent, Task, Crew, Process, LLM\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"CREWAI: ROLE-BASED TEAM EXAMPLE\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Configure LLM for agents (CrewAI native - 2025 recommended)\n",
        "    llm = LLM(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "    \n",
        "    # Define specialized agents with roles\n",
        "    researcher = Agent(\n",
        "        role=\"Senior Researcher\",\n",
        "        goal=\"Gather comprehensive, accurate information on assigned topics\",\n",
        "        backstory=\"\"\"You are an expert researcher with 10 years experience.\n",
        "        You excel at finding reliable sources and extracting key insights.\n",
        "        You are thorough, detail-oriented, and fact-focused.\"\"\",\n",
        "        llm=llm,\n",
        "        verbose=True,\n",
        "        allow_delegation=False\n",
        "    )\n",
        "    \n",
        "    analyst = Agent(\n",
        "        role=\"Data Analyst\",\n",
        "        goal=\"Analyze research findings and identify patterns and insights\",\n",
        "        backstory=\"\"\"You are a skilled data analyst with expertise in\n",
        "        pattern recognition. You excel at turning raw data into actionable insights.\n",
        "        You think critically and identify what matters most.\"\"\",\n",
        "        llm=llm,\n",
        "        verbose=True,\n",
        "        allow_delegation=False\n",
        "    )\n",
        "    \n",
        "    writer = Agent(\n",
        "        role=\"Technical Writer\",\n",
        "        goal=\"Create clear, compelling reports from analysis\",\n",
        "        backstory=\"\"\"You are a professional technical writer with a gift for\n",
        "        making complex topics accessible. You write clearly, concisely, and\n",
        "        engagingly. Your reports are always well-structured and readable.\"\"\",\n",
        "        llm=llm,\n",
        "        verbose=True,\n",
        "        allow_delegation=False\n",
        "    )\n",
        "    \n",
        "    # Define tasks\n",
        "    research_task = Task(\n",
        "        description=\"\"\"Research the following topic in depth:\n",
        "\n",
        "Topic: Multi-agent AI systems in production (2025)\n",
        "\n",
        "Focus on:\n",
        "- Key frameworks (LangGraph, CrewAI, LangChain)\n",
        "- Production patterns\n",
        "- Real-world metrics and ROI\"\"\",\n",
        "        agent=researcher,\n",
        "        expected_output=\"Comprehensive research findings with sources\"\n",
        "    )\n",
        "    \n",
        "    analysis_task = Task(\n",
        "        description=\"\"\"Analyze the research findings and identify:\n",
        "1. Key trends and patterns\n",
        "2. Framework comparison insights\n",
        "3. Production best practices\n",
        "4. Business implications\"\"\",\n",
        "        agent=analyst,\n",
        "        expected_output=\"Analysis report with insights and recommendations\"\n",
        "    )\n",
        "    \n",
        "    writing_task = Task(\n",
        "        description=\"\"\"Write an executive summary that:\n",
        "1. Summarizes key findings\n",
        "2. Highlights most important insights\n",
        "3. Provides clear recommendations\n",
        "4. Is concise (2-3 paragraphs)\n",
        "\n",
        "Audience: Technical decision-makers\"\"\",\n",
        "        agent=writer,\n",
        "        expected_output=\"Professional executive summary\"\n",
        "    )\n",
        "    \n",
        "    # Create crew (team)\n",
        "    crew = Crew(\n",
        "        agents=[researcher, analyst, writer],\n",
        "        tasks=[research_task, analysis_task, writing_task],\n",
        "        process=Process.sequential,  # Tasks run in order\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    # Execute! CrewAI handles coordination automatically\n",
        "    print(\"\\n\ud83d\ude80 Starting CrewAI team execution...\\n\")\n",
        "    result = crew.kickoff()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CREWAI RESULT:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(result)\n",
        "    \n",
        "    print(\"\\n\u2705 CrewAI: Simple role-based API, automatic coordination!\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"\u26a0\ufe0f CrewAI not installed. Install with: pip install crewai\")\n",
        "    print(\"\\nCrewAI Example Structure:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\"\"# 1. Define Agents with Roles\n",
        "researcher = Agent(\n",
        "    role=\"Senior Researcher\",\n",
        "    goal=\"Gather comprehensive information\",\n",
        "    backstory=\"Expert with 10 years experience...\",\n",
        "    llm=llm,  # CrewAI native LLM\n",
        "    verbose=True)\n",
        "\n",
        "# 2. Define Tasks\n",
        "research_task = Task(\n",
        "    description=\"Research topic X...\",\n",
        "    agent=researcher,\n",
        "    expected_output=\"Research findings\")\n",
        "\n",
        "# 3. Create Crew\n",
        "crew = Crew(\n",
        "    agents=[researcher, analyst, writer],\n",
        "    tasks=[research_task, analysis_task, writing_task],\n",
        "    process=Process.sequential)\n",
        "\n",
        "# 4. Execute\n",
        "result = crew.kickoff()\"\"\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\u2705 CrewAI handles all coordination automatically!\")\n",
        "    print(\"\u2705 Role-based API is intuitive and fast to implement\")\n",
        "    print(\"\u2705 Best for: Quick MVPs, role-based teams, moderate complexity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **CrewAI = Simplest + Fastest to Production** - Role-based API, minimal code  \n\u2705 **Built-in collaboration** - Agents coordinate automatically  \n\u2705 **Enterprise-ready** - HIPAA/SOC2, production features  \n\u2705 **2025 independence** - No longer depends on LangChain\n\n**Trade-off**: Less control than LangGraph, more opinionated\n\n**When to use**: Quick MVP, role-based teams, straightforward workflows\n\n**Key Insight**: CrewAI gets you to production fastest!\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 11: Framework Comparison & Decision Guide\n\n### \ud83c\udfaf Learning Objectives\n- Compare LangGraph, CrewAI, LangChain side-by-side\n- Learn decision framework for choosing\n- Understand when to use which framework\n\n### Comprehensive Comparison (2025)\n\n| Feature | LangGraph | CrewAI | LangChain |\n|---------|-----------|--------|-----------|\n| **Performance** | Fastest (2.3s) | Very Fast (2.8s) | Slowest (4.1s) |\n| **Token Usage** | Moderate | Lowest | Highest |\n| **Learning Curve** | Steep | Easy | Moderate |\n| **Control Level** | Maximum | Opinionated | Flexible |\n| **Best For** | Complex workflows | Role-based teams | General LLM apps |\n| **Production Ready** | \u2705 (1.0 Oct 2025) | \u2705 (Enterprise) | \u2705 (Mature) |\n| **Async/Distributed** | \u2705 Built-in | \u2705 Supported | \u26a0\ufe0f Limited |\n| **Memory** | Manual setup | \u2705 Built-in | \u2705 Built-in |\n| **Human-in-Loop** | \u2705 Interrupts | \u2705 Supported | \u26a0\ufe0f Manual |\n| **Multimodal** | \u2705 Via LangChain | \u2705 Native (2025) | \u2705 Yes |\n| **Compliance** | - | \u2705 HIPAA/SOC2 | - |\n\n### Framework Strengths\n\n**LangGraph**:\n- \u2705 Fastest performance\n- \u2705 Maximum control and precision\n- \u2705 Best for complex, dynamic workflows\n- \u274c Steep learning curve\n- \u274c More code required\n\n**CrewAI**:\n- \u2705 Simplest API\n- \u2705 Fastest to production (hours)\n- \u2705 Enterprise compliance\n- \u274c Less customization\n- \u274c Opinionated architecture\n\n**LangChain**:\n- \u2705 Broadest ecosystem\n- \u2705 General-purpose LLM tooling\n- \u2705 Good for document-heavy apps\n- \u274c Highest latency\n- \u274c Highest token costs\n\n### Decision Framework\n\n**Choose LangGraph if**:\n- \u2705 Complex, dynamic workflows\n- \u2705 Performance is critical\n- \u2705 Need maximum control\n- \u2705 Have experienced team\n- \u2705 System will evolve significantly\n\n**Choose CrewAI if**:\n- \u2705 Need MVP quickly\n- \u2705 Role-based team structure\n- \u2705 Moderate complexity\n- \u2705 Enterprise compliance needed\n- \u2705 Team is less experienced\n\n**Choose LangChain if**:\n- \u2705 General LLM application\n- \u2705 Document-heavy RAG system\n- \u2705 Need broad ecosystem\n- \u2705 Performance not critical\n- \u2705 Prototype/research phase\n\n### Real-World Patterns (2025)\n\n**Startup Pattern**:\n1. Start with CrewAI (quick MVP)\n2. Validate product-market fit\n3. Migrate to LangGraph if complexity grows\n\n**Enterprise Pattern**:\n1. LangGraph for core systems (performance)\n2. CrewAI for internal tools (speed)\n3. LangChain for RAG/document apps\n\n**Key Insight**: You can mix frameworks! Use the right tool for each job."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Decision Framework Implementation\ndef choose_framework(requirements: dict) -> str:\n    \"\"\"Decision logic for framework selection\"\"\"\n    complexity = requirements.get(\"complexity\", \"moderate\")\n    timeline = requirements.get(\"timeline\", \"moderate\")\n    team_experience = requirements.get(\"team_experience\", \"moderate\")\n    performance_critical = requirements.get(\"performance_critical\", False)\n    compliance_needed = requirements.get(\"compliance_needed\", False)\n    \n    print(\"=\" * 60)\n    print(\"FRAMEWORK DECISION ANALYSIS\")\n    print(\"=\" * 60)\n    print(f\"Complexity: {complexity}\")\n    print(f\"Timeline: {timeline}\")\n    print(f\"Team Experience: {team_experience}\")\n    print(f\"Performance Critical: {performance_critical}\")\n    print(f\"Compliance Needed: {compliance_needed}\")\n    print(\"\\n\" + \"-\" * 60)\n    \n    # Decision logic\n    if complexity == \"high\" and performance_critical:\n        recommendation = \"LangGraph\"\n        reason = \"Complex workflows with performance requirements need maximum control\"\n    elif timeline == \"urgent\" or team_experience == \"low\":\n        recommendation = \"CrewAI\"\n        reason = \"Quick delivery and ease of use prioritized\"\n    elif compliance_needed:\n        recommendation = \"CrewAI\"\n        reason = \"HIPAA/SOC2 compliance built-in\"\n    elif complexity == \"low\":\n        recommendation = \"LangChain or CrewAI\"\n        reason = \"Simple use case, either works well\"\n    else:\n        recommendation = \"CrewAI \u2192 LangGraph migration path\"\n        reason = \"Start simple, migrate if complexity grows\"\n    \n    print(f\"RECOMMENDATION: {recommendation}\")\n    print(f\"REASONING: {reason}\")\n    print(\"=\" * 60)\n    \n    return recommendation\n\n# Test different scenarios\nprint(\"\\nSCENARIO 1: Startup MVP\")\nchoose_framework({\n    \"complexity\": \"moderate\",\n    \"timeline\": \"urgent\",\n    \"team_experience\": \"moderate\",\n    \"performance_critical\": False})\n\nprint(\"\\n\" + \"=\" * 60 + \"\\n\")\n\nprint(\"SCENARIO 2: Enterprise Fraud Detection\")\nchoose_framework({\n    \"complexity\": \"high\",\n    \"timeline\": \"moderate\",\n    \"team_experience\": \"high\",\n    \"performance_critical\": True,\n    \"compliance_needed\": False})\n\nprint(\"\\n\" + \"=\" * 60 + \"\\n\")\n\nprint(\"SCENARIO 3: Healthcare Application\")\nchoose_framework({\n    \"complexity\": \"moderate\",\n    \"timeline\": \"moderate\",\n    \"team_experience\": \"moderate\",\n    \"performance_critical\": False,\n    \"compliance_needed\": True})\n\nprint(\"\\n\u2705 Decision framework helps choose the right tool for your needs!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcdd Key Takeaways\n\n\u2705 **LangGraph**: Speed + Control (complex systems)  \n\u2705 **CrewAI**: Simplicity + Speed to market (MVPs, role-based)  \n\u2705 **LangChain**: Ecosystem + Flexibility (general apps)\n\n**Decision Strategy**:\n1. Start simple (CrewAI)\n2. Migrate if needed (LangGraph)\n3. Mix frameworks based on use case\n\n**Key Insight**: There's no \"best\" framework - only best framework **for your needs**!\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 12: Production Best Practices\n\n### \ud83c\udfaf Learning Objectives\n- Learn critical production patterns for 2025\n- Implement context engineering\n- Understand memory architecture\n- Know production deployment checklist\n\n### Key Insight (2025)\n\n**\"Scaling multi-agent systems isn't a prompt engineering problem \u2014 it's an infrastructure design problem.\"**\n\n### Critical Success Factors\n\n1. **Context Engineering** (Critical!)\n2. **Memory Architecture**\n3. **Loose Coupling**\n4. **Policy-Driven Control**\n5. **Monitoring & Observability**\n\n### 1. Context Engineering\n\n**Problem**: Naive \"append everything\" approach causes:\n- Context explosion (tokens \u2191\u2191\u2191)\n- Degraded performance\n- Lost focus on relevant information\n\n**Solution**: Treat context as first-class architecture\n\n**Principles**:\n- \u2705 **Selective context** - Only include what's relevant\n- \u2705 **Context boundaries** - Define what each agent sees\n- \u2705 **Summarization** - Compress old context\n- \u2705 **Tiered context** - Recent + Summarized old + Relevant knowledge"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Context Engineering Examples\n\n# \u274c BAD: Append everything (context explosion)\ndef naive_context(conversation_history):\n    \"\"\"Anti-pattern: Just concatenate everything\"\"\"\n    return \"\\n\".join(conversation_history)  # Grows unbounded!\n\n# \u2705 GOOD: Smart context management\ndef smart_context(conversation_history, max_recent=5, query=None):\n    \"\"\"Best practice: Selective, bounded context\"\"\"\n    # 1. Recent context (last N messages)\n    recent = conversation_history[-max_recent:]\n    \n    # 2. Summarize older messages if needed\n    old_summary = None\n    if len(conversation_history) > max_recent:\n        old_messages = conversation_history[:-max_recent]\n        # Summarize old context (simulated)\n        old_summary = f\"Previous discussion covered: {len(old_messages)} messages about various topics\"\n    \n    # 3. Build tiered context\n    context_parts = []\n    if old_summary:\n        context_parts.append(f\"PREVIOUS CONTEXT: {old_summary}\")\n    context_parts.append(f\"RECENT CONVERSATION:\\n\" + \"\\n\".join(recent))\n    \n    return \"\\n\\n\".join(context_parts)\n\n# Demo\nhistory = [\n    \"User: I need help with my account\",\n    \"Agent: Happy to help! What's the issue?\",\n    \"User: I can't log in\",\n    \"Agent: Let me check your account status\",\n    \"User: Thanks\",\n    \"Agent: Your account is active\",\n    \"User: But I still can't log in\",\n    \"Agent: Try resetting your password\"]\n\nprint(\"=\" * 60)\nprint(\"CONTEXT ENGINEERING COMPARISON\")\nprint(\"=\" * 60)\n\nprint(\"\\n\u274c NAIVE APPROACH:\")\nnaive = naive_context(history)\nprint(f\"Length: {len(naive)} chars\")\nprint(naive[:200] + \"...\")\n\nprint(\"\\n\u2705 SMART APPROACH:\")\nsmart = smart_context(history, max_recent=3)\nprint(f\"Length: {len(smart)} chars (reduced!)\")\nprint(smart)\n\nprint(\"\\n\u2705 Context engineering: Selective, bounded, efficient!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Memory Architecture\n\n**Three Types of Memory**:\n1. **Ephemeral** (Redis): Short-term context (session state)\n2. **Persistent** (Vector DB): Long-term knowledge (facts, history)\n3. **Audit** (Structured logs): Decision trace (compliance)\n\n**Pattern**: Separate concerns, use right storage for each type"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Production Memory Architecture (Conceptual)\nclass ProductionMemory:\n    \"\"\"\n    Production-grade memory architecture\n    - Redis: Fast session state (ephemeral)\n    - Chroma/Pinecone: Long-term knowledge (persistent)\n    - Structured logs: Audit trail (compliance)\n    \"\"\"\n    \n    def __init__(self):\n        # In production: real Redis, Vector DB, logging\n        self.ephemeral = {}  # Simulates Redis\n        self.persistent = {}  # Simulates Vector DB\n        self.audit_log = []  # Simulates structured logging\n    \n    def get_context(self, session_id: str, query: str):\n        \"\"\"Retrieve context from multiple sources\"\"\"\n        # 1. Get recent session context (ephemeral)\n        recent = self.ephemeral.get(session_id, [])\n        \n        # 2. Get relevant long-term knowledge (persistent)\n        # In production: vector similarity search\n        relevant = self.persistent.get(query, \"Relevant background knowledge...\")\n        \n        # 3. Log context retrieval (audit)\n        self.audit_log.append({\n            \"action\": \"context_retrieval\",\n            \"session_id\": session_id,\n            \"query\": query,\n            \"timestamp\": \"2025-12-10T10:00:00Z\"\n        })\n        \n        return {\n            \"recent_context\": recent,\n            \"knowledge\": relevant,\n            \"context_size\": len(recent) + len(str(relevant))\n        }\n    \n    def save_context(self, session_id: str, message: str, permanent: bool = False):\n        \"\"\"Save context to appropriate storage\"\"\"\n        # 1. Always save to session (ephemeral)\n        if session_id not in self.ephemeral:\n            self.ephemeral[session_id] = []\n        self.ephemeral[session_id].append(message)\n        \n        # 2. If important, save to long-term (persistent)\n        if permanent:\n            key = f\"knowledge_{len(self.persistent)}\"\n            self.persistent[key] = message\n        \n        # 3. Log save operation (audit)\n        self.audit_log.append({\n            \"action\": \"context_save\",\n            \"session_id\": session_id,\n            \"permanent\": permanent,\n            \"timestamp\": \"2025-12-10T10:00:00Z\"\n        })\n\n# Demo\nmemory = ProductionMemory()\n\nprint(\"=\" * 60)\nprint(\"PRODUCTION MEMORY ARCHITECTURE\")\nprint(\"=\" * 60)\n\n# Save session context\nmemory.save_context(\"session-123\", \"User asked about pricing\")\nmemory.save_context(\"session-123\", \"Agent provided pricing tiers\")\n\n# Save important knowledge permanently\nmemory.save_context(\"session-123\", \"Enterprise tier: $500/month\", permanent=True)\n\n# Retrieve context\ncontext = memory.get_context(\"session-123\", \"pricing\")\nprint(f\"\\nRetrieved context: {context}\")\n\nprint(f\"\\nAudit log entries: {len(memory.audit_log)}\")\nfor entry in memory.audit_log:\n    print(f\"  - {entry['action']}: {entry['session_id']}\")\n\nprint(\"\\n\u2705 Separate memory types: Ephemeral + Persistent + Audit!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Production Deployment Checklist\n\n**Infrastructure**:\n- \u2705 Containerized agents (Docker)\n- \u2705 Clear interfaces (APIs, message queues)\n- \u2705 Horizontal scaling support\n- \u2705 Health checks and monitoring\n\n**Reliability**:\n- \u2705 Error handling and retries\n- \u2705 Circuit breakers for external APIs\n- \u2705 Fallback strategies\n- \u2705 Graceful degradation\n\n**Security**:\n- \u2705 Policy-driven permissions\n- \u2705 Input validation and sanitization\n- \u2705 Output filtering (guardrails)\n- \u2705 Audit logging\n\n**Observability**:\n- \u2705 Comprehensive logging\n- \u2705 Metrics and dashboards\n- \u2705 Decision auditability\n- \u2705 Performance monitoring\n\n**Cost Management**:\n- \u2705 Token usage tracking\n- \u2705 Caching strategies\n- \u2705 Model selection (GPT-4 vs 4o-mini)\n- \u2705 Rate limiting\n\n### \ud83d\udcdd Key Takeaways\n\n\u2705 **Context engineering is critical** - Don't append everything!  \n\u2705 **Memory architecture matters** - Ephemeral + Persistent + Audit  \n\u2705 **Infrastructure over prompts** - Multi-agent = infrastructure problem  \n\u2705 **Production checklist** - Security, reliability, observability\n\n**Key Insight**: Success in production requires engineering discipline, not just better prompts!\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 13: Real-World Case Study - Banking Fraud Detection\n\n### \ud83c\udfaf Learning Objectives\n- See multi-agent systems in production\n- Understand business impact and ROI\n- Learn from real-world architecture\n\n### Case Study: Banking Fraud Detection System\n\n**Organization**: Major bank (unnamed for confidentiality)\n**Timeline**: Deployed 2024-2025\n**Scale**: Processing millions of transactions\n\n### System Overview\n\n**Architecture**: 12-agent hierarchical system\n\n**Results**:\n- \u2705 **96% fraud detection accuracy** (up from 87%)\n- \u2705 **65% reduction in false positives**\n- \u2705 **2.3 second average detection time** (real-time)\n- \u2705 **$18.7M annual savings**\n\n### Agent Structure\n\n**Layer 1 - Coordinator**:\n1. Transaction Router (directs to appropriate detection agents)\n\n**Layer 2 - Signal Detectors** (run in parallel):\n2. Geographic Anomaly Agent\n3. Spending Pattern Agent\n4. Merchant Verification Agent\n5. Device Fingerprint Agent\n6. Velocity Check Agent\n7. Historical Behavior Agent\n\n**Layer 3 - Analysis**:\n8. Risk Aggregation Agent\n9. Confidence Scorer Agent\n\n**Layer 4 - Decision**:\n10. Approval Agent (low risk)\n11. Review Agent (medium risk)\n12. Block Agent (high risk)\n\n### Key Design Decisions\n\n**1. Parallel Processing**: Signal detectors run simultaneously for speed\n**2. Specialized Agents**: Each agent expert in one fraud signal\n**3. Hierarchical Aggregation**: Multiple layers synthesize signals\n**4. Human-in-the-Loop**: Medium risk \u2192 human review\n\n### Why Multi-Agent vs. Monolithic?\n\n**Monolithic Model** (previous system):\n- Single model tries to catch all fraud\n- 87% accuracy\n- High false positives\n- Hard to improve\n\n**Multi-Agent System**:\n- Specialized agents for different signals\n- 96% accuracy\n- 65% fewer false positives\n- Easy to improve individual agents"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Simplified Fraud Detection System (Conceptual)\nfrom typing import TypedDict\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\nclass FraudState(TypedDict):\n    transaction: dict\n    geo_signal: float\n    spending_signal: float\n    merchant_signal: float\n    risk_score: float\n    decision: str\n\n# Signal Detection Agents (run in parallel in production)\ndef geo_anomaly_agent(state: FraudState):\n    \"\"\"Detect geographical anomalies\"\"\"\n    transaction = state['transaction']\n    # Simulated: Check if location matches user pattern\n    location = transaction.get('location', 'USA')\n    usual_location = transaction.get('usual_location', 'USA')\n    \n    # Simple rule (production: ML model)\n    geo_signal = 0.0 if location == usual_location else 0.7\n    print(f\"\ud83c\udf0d GEO AGENT: Location {location} vs usual {usual_location} \u2192 Signal: {geo_signal}\")\n    return {\"geo_signal\": geo_signal}\n\ndef spending_pattern_agent(state: FraudState):\n    \"\"\"Analyze spending patterns\"\"\"\n    transaction = state['transaction']\n    # Simulated: Compare with historical spending\n    amount = transaction.get('amount', 0)\n    avg_amount = transaction.get('avg_transaction', 100)\n    \n    # Simple rule (production: ML model)\n    ratio = amount / avg_amount if avg_amount > 0 else 1\n    spending_signal = min(ratio / 10, 1.0)  # Normalize to 0-1\n    print(f\"\ud83d\udcb3 SPENDING AGENT: ${amount} vs avg ${avg_amount} \u2192 Signal: {spending_signal:.2f}\")\n    return {\"spending_signal\": spending_signal}\n\ndef merchant_verification_agent(state: FraudState):\n    \"\"\"Verify merchant legitimacy\"\"\"\n    transaction = state['transaction']\n    # Simulated: Check merchant database\n    merchant = transaction.get('merchant', 'Unknown')\n    known_merchants = ['Amazon', 'Walmart', 'Target', 'Apple']\n    \n    merchant_signal = 0.0 if merchant in known_merchants else 0.5\n    print(f\"\ud83c\udfea MERCHANT AGENT: {merchant} \u2192 Signal: {merchant_signal}\")\n    return {\"merchant_signal\": merchant_signal}\n\ndef risk_aggregation_agent(state: FraudState):\n    \"\"\"Aggregate all signals into risk score\"\"\"\n    # Weighted average of signals\n    geo = state.get('geo_signal', 0)\n    spending = state.get('spending_signal', 0)\n    merchant = state.get('merchant_signal', 0)\n    \n    # Weighted formula (production: more sophisticated)\n    risk_score = (geo * 0.4) + (spending * 0.4) + (merchant * 0.2)\n    \n    # Decision logic\n    if risk_score < 0.3:\n        decision = \"APPROVE\"\n    elif risk_score < 0.7:\n        decision = \"REVIEW\"  # Human review\n    else:\n        decision = \"BLOCK\"\n    \n    print(f\"\u2696\ufe0f RISK AGGREGATION: Combined score {risk_score:.2f} \u2192 {decision}\")\n    return {\"risk_score\": risk_score, \"decision\": decision}\n\n# Simulate fraud detection\nprint(\"=\" * 60)\nprint(\"FRAUD DETECTION SYSTEM - TEST CASES\")\nprint(\"=\" * 60)\n\n# Test Case 1: Normal transaction\nprint(\"\\nTEST 1: Normal Transaction\")\nprint(\"-\" * 60)\n\ntransaction1 = {\n    \"amount\": 95,\n    \"avg_transaction\": 100,\n    \"location\": \"USA\",\n    \"usual_location\": \"USA\",\n    \"merchant\": \"Amazon\"}\n\nstate1 = {\"transaction\": transaction1}\nstate1.update(geo_anomaly_agent(state1))\nstate1.update(spending_pattern_agent(state1))\nstate1.update(merchant_verification_agent(state1))\nstate1.update(risk_aggregation_agent(state1))\n\nprint(f\"\\n\u2705 DECISION: {state1['decision']} (Risk: {state1['risk_score']:.2f})\")\n\n# Test Case 2: Suspicious transaction\nprint(\"\\n\\nTEST 2: Suspicious Transaction\")\nprint(\"-\" * 60)\n\ntransaction2 = {\n    \"amount\": 5000,\n    \"avg_transaction\": 100,\n    \"location\": \"Nigeria\",\n    \"usual_location\": \"USA\",\n    \"merchant\": \"Unknown Vendor\"}\n\nstate2 = {\"transaction\": transaction2}\nstate2.update(geo_anomaly_agent(state2))\nstate2.update(spending_pattern_agent(state2))\nstate2.update(merchant_verification_agent(state2))\nstate2.update(risk_aggregation_agent(state2))\n\nprint(f\"\\n\ud83d\udeab DECISION: {state2['decision']} (Risk: {state2['risk_score']:.2f})\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SYSTEM IMPACT\")\nprint(\"=\" * 60)\nprint(\"\u2705 96% fraud detection accuracy (up from 87%)\")\nprint(\"\u2705 65% reduction in false positives\")\nprint(\"\u2705 2.3 second average detection time\")\nprint(\"\u2705 $18.7M annual savings\")\nprint(\"\\n\ud83d\udca1 Multi-agent approach: Each agent specializes in one fraud signal\")\nprint(\"\ud83d\udca1 Parallel execution: All agents run simultaneously for speed\")\nprint(\"\ud83d\udca1 Human-in-the-loop: Medium risk transactions reviewed by humans\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Business Impact\n\n**Financial**:\n- $18.7M annual savings\n- 65% reduction in false positives = better customer experience\n- ROI: Paid for itself in < 3 months\n\n**Operational**:\n- Real-time detection (2.3s average)\n- Reduced manual review burden\n- Improved fraud analyst productivity\n\n**Technical**:\n- Modular: Easy to add new fraud signals\n- Scalable: Handles millions of transactions\n- Maintainable: Each agent independently improvable\n\n### Key Success Factors\n\n1. **Specialization**: Each agent expert in one signal\n2. **Parallel execution**: Speed through concurrency\n3. **Hierarchical aggregation**: Synthesize signals intelligently\n4. **Human oversight**: Medium risk \u2192 human review\n5. **Continuous improvement**: Each agent updated independently\n\n### \ud83d\udcdd Key Takeaways\n\n\u2705 **Real business impact** - 96% accuracy, $18.7M savings  \n\u2705 **Multi-agent advantage** - Specialization beats monolithic  \n\u2705 **Production patterns work** - Hierarchy, parallel, human-in-loop  \n\u2705 **ROI is real** - Multi-agent systems pay for themselves\n\n**Key Insight**: Multi-agent systems aren't just research - they're delivering real business value in production!\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Section 14: Summary & Key Takeaways\n\n### \ud83c\udf89 Congratulations!\n\nYou've completed the comprehensive Agent Types & Multi-Agent Systems lab!\n\n### What You Learned\n\n#### Agent Types\n\u2705 **Reactive Agents** - Fast, stateless, rule-based (real-time monitoring)  \n\u2705 **Planning Agents** - Multi-step reasoning, ReAct pattern (complex workflows)  \n\u2705 **Tool-Using Agents** - Environment interaction, function calling (real-world actions)  \n\u2705 **Hybrid Agents** - Memory + Planning + Tools = Production standard (2025)\n\n#### Multi-Agent Patterns\n\u2705 **Sequential Pattern** - Linear pipelines (Extract \u2192 Summarize \u2192 Report)  \n\u2705 **Supervisor Pattern** - Most common! Central coordinator + specialists  \n\u2705 **Hierarchical Pattern** - Multi-layer for complex domains (Planner \u2192 Supervisors \u2192 Specialists)\n\n#### Framework Comparison\n\u2705 **LangGraph** - Fastest, maximum control, complex workflows, steep learning curve  \n\u2705 **CrewAI** - Simplest, fastest to production, role-based teams, enterprise features  \n\u2705 **LangChain** - Broadest ecosystem, general LLM apps, highest latency\n\n#### Production Patterns\n\u2705 **Context Engineering** - Critical! Don't append everything, design context boundaries  \n\u2705 **Memory Architecture** - Ephemeral (Redis) + Persistent (Vector DB) + Audit (Logs)  \n\u2705 **Infrastructure over Prompts** - Multi-agent = infrastructure design problem  \n\u2705 **Production Checklist** - Security, reliability, observability, cost management\n\n#### Real-World Impact\n\u2705 **Banking Fraud** - 96% accuracy, $18.7M savings, 2.3s detection time  \n\u2705 **Market Growth** - $184.8B by 2034, 35%+ CAGR  \n\u2705 **Production Proven** - Enterprise systems using multi-agent architecture\n\n### Key Insights Summary\n\n1. **Hybrid agents are the 2025 standard** - Production needs memory + planning + tools\n2. **Supervisor pattern most common** - 60%+ of systems use central coordinator + specialists\n3. **LangGraph for complex, CrewAI for speed** - Choose based on complexity and timeline\n4. **Context engineering is critical** - Treat context as first-class architectural concern\n5. **Infrastructure over prompts** - Scaling multi-agent = infrastructure design problem\n6. **Real business value** - Multi-agent systems delivering measurable ROI\n\n### Framework Decision Guide\n\n**Start with CrewAI if**:\n- Quick MVP needed\n- Role-based team structure\n- Less experienced team\n- Need enterprise compliance\n\n**Migrate to LangGraph if**:\n- Complexity grows\n- Performance becomes critical\n- Need maximum control\n- System evolving significantly\n\n**Use LangChain if**:\n- General LLM application\n- Document-heavy RAG\n- Broad ecosystem needed\n\n### Next Steps\n\n**1. Practice**: Build your own multi-agent system\n   - Start simple (2-3 agents)\n   - Try different patterns (sequential, supervisor)\n   - Experiment with frameworks\n\n**2. Study Production Patterns**:\n   - Context engineering\n   - Memory architecture\n   - Monitoring and observability\n\n**3. Explore Real-World Examples**:\n   - Banking fraud detection\n   - Insurance claims processing\n   - Customer service automation\n\n### Resources\n\n**Documentation**:\n- [LangGraph](https://www.langchain.com/langgraph) - State machines for agents\n- [CrewAI](https://docs.crewai.com/) - Role-based agent teams\n- [LangChain](https://python.langchain.com/) - General LLM framework\n\n**Architecture Guides**:\n- [Multi-Agent Architectures](https://galileo.ai/blog/architectures-for-multi-agent-systems)\n- [AI Agent Architecture 2025](https://www.lindy.ai/blog/ai-agent-architecture)\n- [Production Patterns](https://developers.googleblog.com/architecting-efficient-context-aware-multi-agent-framework-for-production/)\n\n**Framework Comparisons**:\n- [LangGraph vs CrewAI vs LangChain](https://www.turing.com/resources/ai-agent-frameworks)\n- [AI Agent Frameworks 2025](https://langfuse.com/blog/2025-03-19-ai-agent-comparison)\n\n**Industry Research**:\n- [Multi-Agent Systems Market](https://terralogic.com/multi-agent-ai-systems-why-they-matter-2025/)\n- [Real-World Examples](https://www.xcubelabs.com/blog/10-real-world-examples-of-ai-agents-in-2025/)\n\n### Final Thoughts\n\nMulti-agent AI systems are transforming how we build intelligent applications. The shift from monolithic models to specialized, coordinating agents enables:\n- **Better performance** through specialization\n- **Easier maintenance** through modularity\n- **Real business value** through measurable impact\n\n**Remember**: The best framework is the one that fits **your needs** - complexity, timeline, team, and requirements!\n\n**Thank you for completing this lab!** \ud83c\udf89\n\nNow go build amazing multi-agent systems! \ud83d\ude80\n\n---\n\n**Questions or Feedback?**\n- Review the code examples\n- Experiment with different patterns\n- Share your multi-agent projects!\n\n**Happy Building!** \ud83d\udcaa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}